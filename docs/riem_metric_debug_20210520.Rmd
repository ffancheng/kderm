---
title: "Riemannian metric from manifold learning"
author: "Fan Cheng"
date: "13/05/2021"
output: 
  # prettydoc::html_pretty:
    # theme: cayman
    # theme: flatly
    rmdformats::readthedown:
    toc: true
    float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries, message=FALSE, echo=TRUE}
library(tidyverse)
library(dimRed)
# library(dtplyr)
library(reticulate)
library(viridis)
# library(ks)
library(hdrcde)
library(igraph)
# library(seurat)
library(matrixcalc)
library(akima)
Jmisc::sourceAll(here::here("R/sources"))
```

# Smart meter data for one household

```{r data}
# load(here::here("data/spdemand_3639id336tow.rda"))
# nid <- 1
# ntow <- 336
# 
# train <- spdemand %>%
#   lazy_dt() %>%
#   filter(tow <= ntow,
#          # id <= sort(unique(spdemand[,id]))[nid],
#          id == 1003) %>%
#   dplyr::select(-id, -tow) %>%
#   data.table::as.data.table()
train <- readRDS(here::here("data/spdemand_1id336tow_train.rds"))
(N <- nrow(train))
```

# Metric learning

```{r parameters}
# Parameters fixed
x <- train
s <- 2
k <- 20
method <- "annIsomap"
annmethod <- "kdtree"
distance <- "euclidean"
treetype <- "kd"
searchtype <- "radius" # change searchtype for radius search based on `radius`, or KNN search based on `k`
radius <- .4
```

## Radius searching with k-d trees

```{r, message=FALSE}
metric_isomap <- metricML(x, s = s, k = k, radius = radius, method = method, annmethod = annmethod, eps = 0, distance = distance, treetype = treetype, searchtype = searchtype)
summary(metric_isomap)
```
The function `metricML()` returns a list of 

- the embedding coordinates `embedding` of \N \times \s
- the embedding metric `rmetric` for each point $p \in x$ as an array
- the weighted neighborhood graph as an `igraph` object `weighted_graph`
- the sparse adjacency matrix from the graph `adj_matrix`


## Embedding plots

```{r}
# Comparison of Isomap embedding plot
par(mfrow = c(1, 2))
plot(metric_isomap$embedding, col = viridis::viridis(24)) # metricML
# plot(e@data@data, col = viridis::viridis(24)) # embedding from dimRed, same as metricML()
emb_isomap <-
  feather::read_feather(here::here("data/embedding_isomap_1id336tow.feather"))
plot(emb_isomap$`0`, emb_isomap$`1`, col = viridis::viridis(24)) # embedding from megaman, radius = 0.4
```

## Riemannian metric

```{r}
# Use adjacency matrix as input for metricML and dimRed, then the embedding should be close, as well as the Riemannian metric
metric_isomap$adj_matrix[1:10, 1:10]# renormalized adjacency matrix
metric_isomap$weighted_graph %>% is.connected()
riem_isomap <- metric_isomap$rmetric
riem_isomap[,,1] %>% 
  # isSymmetric()
  matrixcalc::is.positive.definite() # FALSE
```

**The Riemannian metric from the `metricML()` function is now positive definite for all points. **

Now compare it with the megaman output. 

```{r, eval=TRUE}
np = import("numpy")
H_isomap <- np$load(here::here("data/hmatrix_isomap_1id336tow.npy"))
H_isomap[1,,, drop=TRUE] %>% 
  matrixcalc::is.positive.definite() # TRUE

pd <- rep(NA, N)
for (i in 1:N) {
  pd[i] <- 
    riem_isomap[,,i] %>%  # R
    # H_isomap[i,,, drop=TRUE] %>% # Python
      # isSymmetric()
      matrixcalc::is.positive.definite() # FALSE
}
pd %>% sum

# determinant(riem_isomap[,,i])
# mat <- riem_isomap[,,i]
# eigen(mat)
```


## Debug: riemmanien metric not positive definite (DONE)

**Question:** footnote on P15 of the paper, how to decide the constant `c`?

> In the case of heat kernel (1), c = 1/4, which - crucially - is independent of the dimension of M.

```{r, eval=FALSE}
# Function for graph Laplacian
# Input: W: N*N weight matrix for the neighborhood graph, radius: bandwidth parameter
# Output: L: N*N graph Laplacian matrix
Laplacian <- function(W, radius, lambda = 1){
  
  D <- Matrix::Diagonal(x = rowSums(W)^(-lambda)) # inverse of a diagonal matrix
  W1 <- D %*% W %*% D
  D1 <- Matrix::Diagonal(x = 1 / rowSums(W1)) # inverse of Tn1
  L <- 1 / (radius^2 / 4) * (D1 %*% W1 - Matrix::Diagonal(nrow(W))) # c=1/4 for heat kernel, depending on the choice of weights, P15 footnote
  
  return(L)
}
```

```{r, eval=FALSE}
# Function for Riemannian metric for each point
# The Riemannian metric and its dual associated with an embedding Y. 
# The intrinsic dimension d
# The Riemannian metric is currently denoted by G, its dual metric by H, and the Laplacian by L. 
# G at each point is the matrix inverse of H.
riemann_metric <- function(Y, laplacian, d){
  
  # TODO: add dimension check for all inputs
  
  H <- array(NA, dim = c(d, d, nrow(Y)))
  
  for (i in 1:d) {
    for (j in i:d) {
      yij <- Y[, i] * Y[, j]
      H[i, j, ] <- as.vector(0.5 * (laplacian %*% yij - Y[, i] * (laplacian %*% Y[, j]) - Y[, j] * (laplacian %*% Y[, i])))
      H[j, i, ] <- H[i, j, ] # symmetric matrix
    }
  }
  
  ## Pseudo inverse of H gives the final embedding metric h
  ## Array H corresponds to \tilde{H} in Step 4(a)
  ## The embedding metric H is the pseudo inverse of \tilde{H}
  for (i in 1:nrow(Y)) {
    Hsvals <- eigen(H[ , ,i])
    Huu <- Hsvals$vectors
    Hvv <- Hsvals$values[1:d] # top d largest eigenvalues, already sorted in decreasing order
    Hvv1 <- diag(x = 1 / Hvv)
    H[ , ,i] <- Huu %*% Hvv1 %*% t(Huu)
    H[, , i] <- 0.5 * (H[, , i] + t(H[, , i])) # fix not symmetric issue
  }

  return(H)
}
```



<!-- # Plotting -->

<!-- # Plot ellipse to show distortion -->

<!-- Using the Riemannian metric for each point as the covariance and the 2-d embeddings as the mean to plot an ellipse for each point.  -->

<!-- The underlying requirement is that the Riemannian metric needs to be a square positive definite matrix, i.e. `matrixcalc::is.positive.definite()` returns `TRUE`. -->

<!-- ```{r} -->
<!-- emb <- metric_isomap$embedding -->
<!-- i = 1 -->
<!-- mat <- riem_isomap[,,i] # not positive definite for metricML() -->
<!-- center <- c(emb[i,1], emb[i,2]) -->

<!-- mat <- H_isomap[i,,, drop=TRUE] # is.positive.definite for megaman -->

<!-- # mat <- matrix(c(2.2, 0.4, 0.4, 2.8), nrow=2) # covariance matrix -> cov(dataMatrix) -->

<!-- library(ellipse) -->
<!-- # plotcorr(mat) -->
<!-- # plotcorr(solve(mat)) -->
<!-- plot(ellipse::ellipse(mat, center = center, scale = c(1,1)), type = "l", col = "blue", asp = 1) -->

<!-- car::ellipse(center, shape=mat, radius=1, col="red", lty=2) -->
<!-- # library(mixtools) -->
<!-- mixtools::ellipse(mu = center, sigma = mat, type = "l") -->
<!-- ``` -->


# Variable kernel density estimate

For multivariate data, the variable kernel density estimate is given by
$$\hat{f}(x) = n^{-1} \sum_i K_H (x - X_i).$$
```{r}
# 2-d kde
mkde <- function (x, h) {
  # Data is a matrix of n*d
  # H is an array of dimension (d,d,n)
  start <- Sys.time()
  
  n <- nrow(x)
  if (dim(x)[2] < 2)
    stop("Data matrix has only one variable.")
  if (any(!is.finite(x))) 
    stop("Missing or infinite values in the data are not allowed! ")
  if (!all.equal(nrow(h), ncol(h), dim(x)[2]))
    stop("The bandwidth matrix is of wrong dimension. ")
  
  s <- rep(0, n)
  y <- rep(0, n)
  for (i in 1:n) {
    for (j in 1:n){
      s[i] <- s[i] + abs(det(h[,,i]))^(-1/2) * exp(- 1/2 * t(x[i,] - x[j,]) %*% solve(h[,,i]) %*% (x[i,] - x[j,]))
    }
    y[i] <- s[i] / (n * 2 * pi)
  }
  print(Sys.time() - start) 

  return(y)
}
```


# Test the variable KDE function with megaman output

If we use the embedding `x` and the Riemannian metric `h` from `megaman`, we could produce contour plots. 

```{r pycontour, eval=T}
x <- cbind(emb_isomap$`0`, emb_isomap$`1`)
pyriem_isomap <- array(NA, dim = c(s, s, N))
for(i in 1:N){
  pyriem_isomap[,,i] <- H_isomap[i,,]
}
f <- mkde(x = x, h = pyriem_isomap)
summary(f)
# Top 20 index with the lowest densities
head(order(f), n=20)
```


## Contour plot for megaman

```{r}
embed_den <- as_tibble(cbind(x = x[,1], y = x[,2], z = f)) %>%
  drop_na()
# library(akima)
pixel <- 100
lenbreak <- 5
akima.spl <- interp(embed_den$x, embed_den$y, embed_den$z, nx=pixel, ny=pixel, linear=FALSE)
p.zmin <- min(embed_den$z,na.rm=TRUE)
p.zmax <- max(embed_den$z,na.rm=TRUE)
breaks <- pretty(c(p.zmin,p.zmax), lenbreak)
# hdrcde
hdrscatterplot(embed_den$x, embed_den$y, noutliers = 10)
hdrinfo <- hdr.2d(embed_den$x, embed_den$y, prob = c(50, 95, 99))
plot.hdr2d(hdrinfo)
# Contour
contour(akima.spl, main = "smooth interp(*, linear = FALSE)", col = viridis(length(breaks)-1), levels=breaks, add=TRUE)
points(embed_den, pch = 20)

filled.contour(akima.spl, color.palette = viridis,
               plot.axes = { axis(1); axis(2);
                 title("smooth interp(*, linear = FALSE)");
                 points(embed_den, pch = 3, col= hcl(c=20, l = 10))})

```


# Contour plot after interpolation for R metricML()

Now apply the `mkde()` function to the output of `metricML()` written in R. 

```{r rdensity}
x <- metric_isomap$embedding
riem_isomap <- metric_isomap$rmetric
f <- mkde(x = x, h = riem_isomap)
summary(f)
head(order(f), n=20)
```

We can check the outliers based on density `f`. In R, the outliers are different from `megaman` output. 
```{r, echo=FALSE}
embed_den <- as_tibble(cbind(x = x[,1], y = x[,2], z = f)) %>%
  drop_na()
# library(akima)
pixel <- 100
lenbreak <- 5
akima.spl <- interp(embed_den$x, embed_den$y, embed_den$z, nx=pixel, ny=pixel, linear=FALSE)
p.zmin <- min(embed_den$z,na.rm=TRUE)
p.zmax <- max(embed_den$z,na.rm=TRUE)
breaks <- pretty(c(p.zmin,p.zmax), lenbreak)
# hdrcde
hdrscatterplot(embed_den$x, embed_den$y, noutliers = 10)
hdrinfo <- hdr.2d(embed_den$x, embed_den$y, prob = c(50, 95, 99))
plot.hdr2d(hdrinfo)
# Contour
contour(akima.spl, main = "smooth interp(*, linear = FALSE)", col = viridis(length(breaks)-1), levels=breaks, add=TRUE)
points(embed_den, pch = 20)

filled.contour(akima.spl, color.palette = viridis,
               plot.axes = { axis(1); axis(2);
                 title("smooth interp(*, linear = FALSE)");
                 points(embed_den, pch = 3, col= hcl(c=20, l = 10))})

```

